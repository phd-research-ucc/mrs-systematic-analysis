[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Systematic Review of Medical Resource Scheduling: Draft",
    "section": "",
    "text": "Preface\nThis is a general draft of the review article. The purpose of this document is comfortable‚Ä¶"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2¬† Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee (123?) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3¬† Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. ‚ÄúLiterate Programming.‚Äù Comput.\nJ. 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "section/02_introduction.html#rationale",
    "href": "section/02_introduction.html#rationale",
    "title": "1¬† Introduction",
    "section": "1.1 Rationale",
    "text": "1.1 Rationale\nThis is a book created from markdown and executable code."
  },
  {
    "objectID": "section/02_introduction.html#objectives",
    "href": "section/02_introduction.html#objectives",
    "title": "1¬† Introduction",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nSee @123 for additional discussion of literate programming."
  },
  {
    "objectID": "section/01_introduction.html#rationale",
    "href": "section/01_introduction.html#rationale",
    "title": "1¬† Introduction",
    "section": "1.1 Rationale",
    "text": "1.1 Rationale\n\n\nDescribe the current state of knowledge and its uncertainties.\nArticulate why it is important to do the review.\nIf other systematic reviews addressing the same (or a largely similar) question are available, explain why the current review was considered necessary. If the review is an update or replication of a particular systematic review, indicate this and cite the previous review.\nIf the review examines the effects of interventions, also briefly describe how the intervention(s) examined might work.\nIf there is complexity in the intervention or context of its delivery (or both) (e.g.¬†multi-component interventions, equity considerations), consider presenting a logic model to visually display the hypothesised relationship between intervention components and outcomes."
  },
  {
    "objectID": "section/01_introduction.html#objectives",
    "href": "section/01_introduction.html#objectives",
    "title": "1¬† Introduction",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\n\n\nProvide an explicit statement of all objective(s) or question(s) the review addresses, expressed in terms of a relevant question formulation framework.\nIf the purpose is to evaluate the effects of interventions, use the Population, Intervention, Comparator, Outcome (PICO) framework or one of its variants, to state the comparisons that will be made."
  },
  {
    "objectID": "section/02_methods.html#eligibility-criteria",
    "href": "section/02_methods.html#eligibility-criteria",
    "title": "2¬† Methods",
    "section": "2.1 Eligibility Criteria",
    "text": "2.1 Eligibility Criteria\n\n\nSpecify all study characteristics used to decide whether a study was eligible for inclusion in the review, that is, components described in the PICO framework or one of its variants, and other characteristics, such as eligible study design(s) and setting(s), and minimum duration of follow-up.\nSpecify eligibility criteria with regard to report characteristics, such as year of dissemination, language, and report status (e.g.¬†whether reports, such as unpublished manuscripts and conference abstracts, were eligible for inclusion).\nClearly indicate if studies were ineligible because the outcomes of interest were not measured, or ineligible because the results for the outcome of interest were not reported.\nSpecify any groups used in the synthesis (e.g.¬†intervention, outcome and population groups) and link these to the comparisons specified in the objectives (item #4).\nConsider providing rationales for any notable restrictions to study eligibility."
  },
  {
    "objectID": "section/02_methods.html#information-sources",
    "href": "section/02_methods.html#information-sources",
    "title": "2¬† Methods",
    "section": "2.2 Information Sources",
    "text": "2.2 Information Sources\n\n\nSpecify the date when each source (e.g.¬†database, register, website, organisation) was last searched or consulted.\nIf bibliographic databases were searched, specify for each database its name (e.g.¬†MEDLINE, CINAHL), the interface or platform through which the database was searched (e.g.¬†Ovid, EBSCOhost), and the dates of coverage (where this information is provided).\nIf study registers, regulatory databases and other online repositories were searched, specify the name of each source and any date restrictions that were applied.\nIf websites, search engines or other online sources were browsed or searched, specify the name and URL of each source.\nIf organisations or manufacturers were contacted to identify studies, specify the name of each source.\nIf individuals were contacted to identify studies, specify the types of individuals contacted (e.g.¬†authors of studies included in the review or researchers with expertise in the area).\nIf reference lists were examined, specify the types of references examined (e.g.¬†references cited in study reports included in the systematic review, or references cited in systematic review reports on the same or similar topic).\nIf cited or citing reference searches (also called backward and forward citation searching) were conducted, specify the bibliographic details of the reports to which citation searching was applied, the citation index or platform used (e.g.¬†Web of Science), and the date the citation searching was done.\nIf journals or conference proceedings were consulted, specify of the names of each source, the dates covered and how they were searched (e.g.¬†hand searching or browsing online)."
  },
  {
    "objectID": "section/02_methods.html#search-strategy",
    "href": "section/02_methods.html#search-strategy",
    "title": "2¬† Methods",
    "section": "2.3 Search Strategy",
    "text": "2.3 Search Strategy\n\n\nProvide the full line by line search strategy as run in each database with a sophisticated interface (such as Ovid), or the sequence of terms that were used to search simpler interfaces, such as search engines or websites.\nDescribe any limits applied to the search strategy (e.g.¬†date or language) and justify these by linking back to the review‚Äôs eligibility criteria.\nIf published approaches, including search filters designed to retrieve specific types of records or search strategies from other systematic reviews, were used, cite them. If published approaches were adapted, for example if search filters are amended, note the changes made.\nIf natural language processing or text frequency analysis tools were used to identify or refine keywords, synonyms or subject indexing terms to use in the search strategy, specify the tool(s) used.\nIf a tool was used to automatically translate search strings for one database to another, specify the tool used.\nIf the search strategy was validated, for example by evaluating whether it could identify a set of clearly eligible studies, report the validation process used and specify which studies were included in the validation set.\nIf the search strategy was peer reviewed, report the peer review process used and specify any tool used such as the Peer Review of Electronic Search Strategies (PRESS) checklist.\nIf the search strategy structure adopted was not based on a PICO-style approach, describe the final conceptual structure and any explorations that were undertaken to achieve it."
  },
  {
    "objectID": "section/02_methods.html#selection-process",
    "href": "section/02_methods.html#selection-process",
    "title": "2¬† Methods",
    "section": "2.4 Selection Process",
    "text": "2.4 Selection Process\n\nRecommendations for reporting regardless of the selection processes used:\n\nReport how many reviewers screened each record (title/abstract) and each report retrieved, whether multiple reviewers worked independently at each stage of screening or not, and any processes used to resolve disagreements between screeners.\nReport any processes used to obtain or confirm relevant information from study investigators.\nIf abstracts or articles required translation into another language to determine their eligibility, report how these were translated.\n\nRecommendations for reporting in systematic reviews using automation tools in the selection process:\n\nReport how automation tools were integrated within the overall study selection process.\nIf an externally derived machine learning classifier was applied (e.g.¬†Cochrane RCT Classifier), either to eliminate records or to replace a single screener, include a reference or URL to the version used. If the classifier was used to eliminate records before screening, report the number eliminated in the PRISMA flow diagram as ‚ÄòRecords marked as ineligible by automation tools‚Äô.\nIf an internally derived machine learning classifier was used to assist with the screening process, identify the software/classifier and version, describe how it was used (e.g.¬†to remove records or replace a single screener) and trained (if relevant), and what internal or external validation was done to understand the risk of missed studies or incorrect classifications.\nIf machine learning algorithms were used to prioritise screening (whereby unscreened records are continually re-ordered based on screening decisions), state the software used and provide details of any screening rules applied.\n\nRecommendations for reporting in systematic reviews using crowdsourcing or previous ‚Äòknown‚Äô assessments in the selection process:\n\nIf crowdsourcing was used to screen records, provide details of the platform used and specify how it was integrated within the overall study selection process.\nIf datasets of already-screened records were used to eliminate records retrieved by the search from further consideration, briefly describe the derivation of these datasets."
  },
  {
    "objectID": "section/02_methods.html#data-collection-process",
    "href": "section/02_methods.html#data-collection-process",
    "title": "2¬† Methods",
    "section": "2.5 Data Collection Process",
    "text": "2.5 Data Collection Process\n\n\nReport how many reviewers collected data from each report, whether multiple reviewers worked independently or not, and any processes used to resolve disagreements between data collectors.\nReport any processes used to obtain or confirm relevant data from study investigators.\nIf any automation tools were used to collect data, report how the tool was used, how the tool was trained, and what internal or external validation was done to understand the risk of incorrect extractions.\nIf articles required translation into another language to enable data collection, report how these articles were translated.\nIf any software was used to extract data from figures, specify the software used.\nIf any decision rules were used to select data from multiple reports corresponding to a study, and any steps were taken to resolve inconsistencies across reports, report the rules and steps used."
  },
  {
    "objectID": "section/02_methods.html#data-items",
    "href": "section/02_methods.html#data-items",
    "title": "2¬† Methods",
    "section": "2.6 Data Items",
    "text": "2.6 Data Items\n\n2.6.1 Outcomes\n\n\nList and define the outcome domains and time frame of measurement for which data were sought.\nSpecify whether all results that were compatible with each outcome domain in each study were sought, and if not, what process was used to select results within eligible domains.\nIf any changes were made to the inclusion or definition of the outcome domains, or to the importance given to them in the review, specify the changes, along with a rationale.\nIf any changes were made to the processes used to select results within eligible outcome domains, specify the changes, along with a rationale.\nConsider specifying which outcome domains were considered the most important for interpreting the review‚Äôs conclusions and provide rationale for the labelling (e.g.¬†‚Äúa recent core outcome set identified the outcomes labelled ‚Äòcritical‚Äô as being the most important to patients‚Äù).\n\n\n\n\n2.6.2 Other Variables\n\n\nList and define all other variables for which data were sought (e.g.¬†participant and intervention characteristics, funding sources).\nDescribe any assumptions made about any missing or unclear information from the studies.\nIf a tool was used to inform which data items to collect, cite the tool used."
  },
  {
    "objectID": "section/02_methods.html#study-risk-of-bias-assessment",
    "href": "section/02_methods.html#study-risk-of-bias-assessment",
    "title": "2¬† Methods",
    "section": "2.7 Study Risk of Bias Assessment",
    "text": "2.7 Study Risk of Bias Assessment\n\n\nSpecify the tool(s) (and version) used to assess risk of bias in the included studies.\nSpecify the methodological domains/components/items of the risk of bias tool(s) used.\nReport whether an overall risk of bias judgement that summarised across domains/components/items was made, and if so, what rules were used to reach an overall judgement.\nIf any adaptations to an existing tool to assess risk of bias in studies were made, specify the adaptations.\nIf a new risk of bias tool was developed for use in the review, describe the content of the tool and make it publicly accessible.\nReport how many reviewers assessed risk of bias in each study, whether multiple reviewers worked independently, and any processes used to resolve disagreements between assessors.\nReport any processes used to obtain or confirm relevant information from study investigators.\nIf an automation tool was used to assess risk of bias, report how the automation tool was used, how the tool was trained, and details on the tool‚Äôs performance and internal validation."
  },
  {
    "objectID": "section/02_methods.html#effect-measures",
    "href": "section/02_methods.html#effect-measures",
    "title": "2¬† Methods",
    "section": "2.8 Effect Measures",
    "text": "2.8 Effect Measures\n\n\nSpecify for each outcome (or type of outcome [e.g.¬†binary, continuous]), the effect measure(s) (e.g.¬†risk ratio, mean difference) used in the synthesis or presentation of results.\nState any thresholds (or ranges) used to interpret the size of effect (e.g.¬†minimally important difference; ranges for no/trivial, small, moderate and large effects) and the rationale for these thresholds.\nIf synthesized results were re-expressed to a different effect measure, report the method used to re-express results (e.g.¬†meta-analysing risk ratios and computing an absolute risk reduction based on an assumed comparator risk).\nConsider providing justification for the choice of effect measure."
  },
  {
    "objectID": "section/02_methods.html#synthesis-methods",
    "href": "section/02_methods.html#synthesis-methods",
    "title": "2¬† Methods",
    "section": "2.9 Synthesis Methods",
    "text": "2.9 Synthesis Methods\n\n2.9.1 Eligibility for Synthesis\n\nDescribe the processes used to decide which studies were eligible for each synthesis.\n\n\n\n2.9.2 Preparing for Synthesis\n\nReport any methods required to prepare the data collected from studies for presentation or synthesis, such as handling of missing summary statistics, or data conversions.\n\n\n\n2.9.3 Tabulation and Graphical Methods\n\n\nReport chosen tabular structure(s) used to display results of individual studies and syntheses, along with details of the data presented.\nReport chosen graphical methods used to visually display results of individual studies and syntheses.\nIf studies are ordered or grouped within tables or graphs based on study characteristics (e.g.¬†by size of the study effect, year of publication), consider reporting the basis for the chosen ordering/grouping.\nIf non-standard graphs were used, consider reporting the rationale for selecting the chosen graph.\n\n\n\n\n2.9.4 Statistical Synthesis Methods\n\n\nIf statistical synthesis methods were used, reference the software, packages and version numbers used to implement synthesis methods.\nIf it was not possible to conduct a meta-analysis, describe and justify the synthesis methods or summary approach used.\nIf meta-analysis was done, specify:\n\nthe meta-analysis model (fixed-effect, fixed-effects or random-effects) and provide rationale for the selected model.\nthe method used (e.g.¬†Mantel-Haenszel, inverse-variance).\nany methods used to identify or quantify statistical heterogeneity (e.g.¬†visual inspection of results, a formal statistical test for heterogeneity, heterogeneity variance (ùúè2), inconsistency (e.g.¬†I2), and prediction intervals).\n\nIf a random-effects meta-analysis model was used:\n\nspecify the between-study (heterogeneity) variance estimator used (e.g.¬†DerSimonian and Laird, restricted maximum likelihood (REML)).\nspecify the method used to calculate the confidence interval for the summary effect (e.g.¬†Wald-type confidence interval, Hartung-Knapp-Sidik-Jonkman).\nconsider specifying other details about the methods used, such as the method for calculating confidence limits for the heterogeneity variance.\n\nIf a Bayesian approach to meta-analysis was used, describe the prior distributions about quantities of interest (e.g.¬†intervention effect being analysed, amount of heterogeneity in results across studies).\nIf multiple effect estimates from a study were included in a meta-analysis, describe the method(s) used to model or account for the statistical dependency (e.g.¬†multivariate meta-analysis, multilevel models or robust variance estimation).\nIf a planned synthesis was not considered possible or appropriate, report this and the reason for that decision.\n\n\n\n\n2.9.5 Methods to Explore Heterogeneity\n\n\nIf methods were used to explore possible causes of statistical heterogeneity, specify the method used (e.g.¬†subgroup analysis, meta-regression).\nIf subgroup analysis or meta-regression was performed, specify for each:\n\nwhich factors were explored, levels of those factors, and which direction of effect modification was expected and why (where possible).\nwhether analyses were conducted using study-level variables (i.e.¬†where each study is included in one subgroup only), within-study contrasts (i.e.¬†where data on subsets of participants within a study are available, allowing the study to be included in more than one subgroup), or some combination of the above.\nhow subgroup effects were compared (e.g.¬†statistical test for interaction for subgroup analyses).\n\nIf other methods were used to explore heterogeneity because data were not amenable to meta-analysis of effect estimates (e.g.¬†structuring tables to examine variation in results across studies based on subpopulation), describe the methods used, along with the factors and levels.\nIf any analyses used to explore heterogeneity were not pre-specified, identify them as such.\n\n\n\n\n2.9.6 Sensitivity Analyses\n\n\nIf sensitivity analyses were performed, provide details of each analysis (e.g.¬†removal of studies at high risk of bias, use of an alternative meta-analysis model).\nIf any sensitivity analyses were not pre-specified, identify them as such."
  },
  {
    "objectID": "section/02_methods.html#reporting-bias-assessment",
    "href": "section/02_methods.html#reporting-bias-assessment",
    "title": "2¬† Methods",
    "section": "2.10 Reporting Bias Assessment",
    "text": "2.10 Reporting Bias Assessment\n\n\nSpecify the methods (tool, graphical, statistical or other) used to assess the risk of bias due to missing results in a synthesis (arising from reporting biases).\nIf risk of bias due to missing results was assessed using an existing tool, specify the methodological components/domains/items of the tool, and the process used to reach a judgement of overall risk of bias.\nIf any adaptations to an existing tool to assess risk of bias due to missing results were made, specify the adaptations.\nIf a new tool to assess risk of bias due to missing results was developed for use in the review, describe the content of the tool and make it publicly accessible.\nReport how many reviewers assessed risk of bias due to missing results in a synthesis, whether multiple reviewers worked independently, and any processes used to resolve disagreements between assessors.\nReport any processes used to obtain or confirm relevant information from study investigators.\nIf an automation tool was used to assess risk of bias due to missing results, report how the automation tool was used, how the tool was trained, and details on the tool‚Äôs performance and internal validation."
  },
  {
    "objectID": "section/02_methods.html#certainty-assessment",
    "href": "section/02_methods.html#certainty-assessment",
    "title": "2¬† Methods",
    "section": "2.11 Certainty Assessment",
    "text": "2.11 Certainty Assessment\n\n\nSpecify the tool or system (and version) used to assess certainty (or confidence) in the body of evidence.\nReport the factors considered (e.g.¬†precision of the effect estimate, consistency of findings across studies) and the criteria used to assess each factor when assessing certainty in the body of evidence.\nDescribe the decision rules used to arrive at an overall judgement of the level of certainty, together with the intended interpretation (or definition) of each level of certainty.\nIf applicable, report any review-specific considerations for assessing certainty, such as thresholds used to assess imprecision and ranges of magnitude of effect that might be considered trivial, moderate or large, and the rationale for these thresholds and ranges (item #12).\nIf any adaptations to an existing tool or system to assess certainty were made, specify the adaptations.\nReport how many reviewers assessed certainty in the body of evidence for an outcome, whether multiple reviewers worked independently, and any processes used to resolve disagreements between assessors.\nReport any processes used to obtain or confirm relevant information from investigators.\nIf an automation tool was used to support the assessment of certainty, report how the automation tool was used, how the tool was trained, and details on the tool‚Äôs performance and internal validation.\nDescribe methods for reporting the results of assessments of certainty, such as the use of Summary of Findings tables.\nIf standard phrases that incorporate the certainty of evidence were used (e.g.¬†‚Äúhip protectors probably reduce the risk of hip fracture slightly‚Äù), report the intended interpretation of each phrase and the reference for the source guidance."
  },
  {
    "objectID": "section/03_results.html#study-selection",
    "href": "section/03_results.html#study-selection",
    "title": "3¬† Results",
    "section": "3.1 Study Selection",
    "text": "3.1 Study Selection\nIn this systematic literature review the initial search in the five research databases returned TOTAL_OF_SEARCHED_STUDIES which gone over the initial screening phase, where the most suitable studies based on the titles have been selected. Next from the screened materials the list of studies for review was created (filtration based on the abstracts). On the listing phase some of the papers may be categorised in the groups. After that, the scanning review was performed. During the scanning review, the main focus in on the summary of the work in abstract and conclusion, objectives, and resulting tables and plots. Based on the extracted data after the scanning the rest of the studies without the group are allocated to the proper group and identified for the next stage. Next stage is focus review for extracting all characteristics of the studies. The best works went over the in-depth analysis which is the final stage of data gathering process. On the each stage the studies were filterd for efficient use of time resource.\n\n3.1.1 Flow of Studies\nIn this subsection the study flow is presented with quantitative characteristics for each stage of the review. The flow diagram below underlines the number of studies which were searched in the five databeses, overlaping duplicates amoung databases, and the remaining works after each review stage.\nPRISMA FLOW DIAGRAM FOR STUDY FLOW\nVENN DIAGRAMS FOR SEARCH DUPLICATES AMOUNG DATABASES\n\n\n3.1.2 Excluded Studies\nCITE STUDIES THAT MIGHT APPEAR TO MEET THE INCLUSION CRITERIA, BUT WHICH WERE EXCLUDED, AND EXPLAIN WHY THEY WERE EXCLUDED"
  },
  {
    "objectID": "section/03_results.html#study-characteristics",
    "href": "section/03_results.html#study-characteristics",
    "title": "3¬† Results",
    "section": "3.2 Study Characteristics",
    "text": "3.2 Study Characteristics\nPRESENT THE KEY CHARACTERISTICS OF EACH STUDY (POSSIBLY ADD THIS AS APENDIX SINCE EVEN IF LIST 10 TOP STUDIES FOR EACH CATEGORY IT WILL OCCUPY A LOT OF SPACE)"
  },
  {
    "objectID": "section/03_results.html#risk-of-bias-in-studies",
    "href": "section/03_results.html#risk-of-bias-in-studies",
    "title": "3¬† Results",
    "section": "3.3 Risk of Bias in Studies",
    "text": "3.3 Risk of Bias in Studies\nThe general risk of bias in studies is demonstrated for the selected top 10 of studies based on the certainty level and general grade of the each individual study. The overal certainty analysis of the reviewed materials is presented at the end of the result section.\nTABLE OF THE CERTAINTY OF TOP 10 STUDIES"
  },
  {
    "objectID": "section/03_results.html#results-of-individual-studies",
    "href": "section/03_results.html#results-of-individual-studies",
    "title": "3¬† Results",
    "section": "3.4 Results of Individual Studies",
    "text": "3.4 Results of Individual Studies\nIn this subsection the are described in greater details top works in the medical resource scheduling field. The superiority of the studies was defined by the general grade of the scientific investigator and also the level of relativity to the subject. In other words, the materials rated ‚ÄôA+‚Äôand with maximum relativity score are selected for in-depth analysis and demonstration of outcomes.\nGO FROM STUDY TO STUDY AND USE ONE PHARAGRAPH PER STUDY"
  },
  {
    "objectID": "section/03_results.html#results-of-syntheses",
    "href": "section/03_results.html#results-of-syntheses",
    "title": "3¬† Results",
    "section": "3.5 Results of Syntheses",
    "text": "3.5 Results of Syntheses\nIn this section the outcomes of the analysis syntheses on the papers combined into three subgroups that present data-driven, process-driven, and hybrid solutions to the medical resource scheduling problem. The meta-analysis demonstrates the advantages and disadvanatages of the approaches in scope of robustness, applocability, and the complexoty of the models.\n\n3.5.1 Characteristics of Contributing Studies\nThere are three main charactersitics of the research studies which are analysed in this review. The first is robustness of the medical resource scheduler. The second represents the applicability of the proposed solutions in real hospitals. The final characteristic shows the complexity of the model based on the problem formulation in each case. Secondary features such as level of integration and decision-making of the models and location of the researchers and the implemented solutions were also extracted from the reviewed works.\n\n\n3.5.2 Results of Statistical Syntheses\nThe subsection demonstrates results in seven investigated aspects: robusntess, applicability, complexity, integtry of the solutions, also what levels of desicion-making are the most often researched for the last three years, what countries have the most scientific potential in scope of human resources, and finally the most progressive countries in terms of researching for needs of a specific hospitals. All this aspects have their own subgroups of data-driven and process-driven approaches, and some topycs are overlapping to showcase discribution of the study in the medical resource scheduling.\n\n3.5.2.1 Data on Robustness\nFor multiple reasons the parameter of robustness is much higher for the theoretical stadies then in practical applicable solutions. The first reason is that the number of data-driven, in particular deep learning, approaches is drastically increased for the last years. The focus on historical data is beneficial for applicability of the result, but in cost of robustness of the model, which makes it harder to apply the same model for multiple solutions but with slitelly different environment and input data. Second lab models are more idealised, and thus more inclusive than complex realistic models. And finally, most of the hospitals in the studies work almost independantly for other healthcare facilities especially with facilities in other countries. This strategy gains quick local benefits but also reduces generasability of the hospital protocols for other developing hospitals.\nTHE PLOT SHOWCASES ROBUSTNESS FOR STUDIES ON DATA-DRIVEN, PROCESS-DRIVEN, AND HYBRIT APPROACHES FOR THE AT-LEAST LAST THREE YEARS\n\n\n3.5.2.2 Data on Applicability\nThe applicability score is driven from actual model implementation in the real hospitals. If the model works on the sentatic data generated from the real medical records, it gains plus one point of applicability, if the model works on the real data - plus two points, if the model is implemented in real environment it has three points, if the model works in real time it is four points, and finally if the model is integrated with the general healthcare record system it is five-point of applicability to this solution. Clearly data-driven solutions ar in the lead of applicability for the last three years, doe to increased interest to deep learning models for healthcare applications.\nTHE PLOT SHOWCASES APPLICABILITY FOR STUDIES ON DATA-DRIVEN, PROCESS-DRIVEN, AND HYBRIT APPROACHES FOR THE AT-LEAST LAST THREE YEARS\n\n\n3.5.2.3 Data on Complexity\nThe complexity and the applicability of the medical resource scheduling problem are clossely related. Especially when there is no way to compare the developing process and the design solution amoung themselves. Nevertheless each additional constraint in the model specification introduces additional complexity.\nTHE PLOT SHOWCASES COMPLEXITY FOR STUDIES ON DATA-DRIVEN, PROCESS-DRIVEN, AND HYBRIT APPROACHES FOR THE AT-LEAST LAST THREE YEARS\n\n\n3.5.2.4 Data on Integrated Solutions\nThe results on level of integrations are simmilar to the complexity characteristic of the reviewed studies. Nevertheless, complex scheduling is not always highly-integrated. The problem deffinition can be consentraited specifically on-to operating theatre and consider all possible timing charateristics of the scheduling problems but not take into account upstream and downstream capacities. Therefore, complexity relates to depth and width of the problem components when integrity highlights only the width of the scheduling problem.\nTHE PLOT SHOWCASES COMPLEXITY FOR STUDIES ON DATA-DRIVEN, PROCESS-DRIVEN, AND HYBRIT APPROACHES FOR THE AT-LEAST LAST THREE YEARS\n\n\n3.5.2.5 Data on Level of Decision-Making\nThe plots of three reviewed charactersitics in relation to decision-making levels show the distribution of approaches amoung the strategical, tactical, and operational levels of decision. The studies where the decision level was not identified are not included in this analysis.\nTHE PLOT OF ROBUSTNESS, APPLICABILITY, AND COMPLEXITY OF SOLUTIONS FOR EACH DECISION-MAKING LEVEL\n\n\n3.5.2.6 The Human-Scientific Potential\nThe plots below show the scientific-human potential based on the number of affiliations for operational research in healthcare. The duplicates of affiliations have been removed before the analysis. The most reserchers in the area of medical resource scheduling are consentraited in United States, China, and Iran.\nTHE PLOT IS A GLOBAL MAP WHICH SHOWS THE COUNTRIES WITH THE RESEARCHERS ON THE FIELD OF MEDICAL RESOURCE SCHEDULING\n\n\n3.5.2.7 Localisation of the Studies\nThis analysis is similar to the previous chart, but this shows locations where the studies are actually implemented. This time the Netherlands are showing much higher rate of implementation of the scietific results then China and Iran, and climebs onto the second position by the number of implemented studies in real healthcare facilities.\nTHE PLOT SHOWS A GLOBAL MAP WITH COUNTRIES WITH THE HEALTHCARE FACILITIES WHICH PARTISIPATED IN MEDICAL RESOURCE SCHEDULING RESEARCHES\n\n\n\n3.5.3 Results of Investigation of Heterogeneity\nFor the study of this scope the identification of the studies which can be effectively compared and analysed on bias within the sertain borders is not a trivial task. First of all, even the medical resource scheduling problem goes under umbrella of one term, there are numerouse problems which this term contains. And even, for example, if the operating theatre scheduling is considered as a focal point of the research, the problem formulationions for that segment of scheduling problems varies greatly. Therefore, to unify measuring criteria for the reviewed, it was desided to compare the studies based on the three metrices: robustness, applicability, and complexity.\nPRESENT THE GENERAL RESULTS WITH HETEROGENEITY TABLE FOR DATA-DRIVEN, PROCESS-DRIVEN, AND HYBRID SOLUTIONS\n\n3.5.3.1 Robustness:\nThe data-driven methods show better robustness then other approaches. The wide data used in the data-driven algorithm increases the focus of the modules to a specific environments. This make machine learning approaches less scalable for different scenarios in the same area of schedulig medical resources. If consider some general advisory system which will serve a veriaty of hospitals there is a requirements for protocols of processes to which the system will resert when there is no hystoric data available.\nPRESENT FOREST TREES OF WORKS REGARDIGN ROBUSTNESS FOR EACH SUBGROUP BASED ON PROBLEM DEFFINITION\n\n\n3.5.3.2 Applicability:\nThe major consern is that most of the work consentraited on the non-applicable solutions. Hopefully the interest in deep learning solutions tip this scale in the favor of more applicability of the scheduling models. It is easy to see that data-driven and hybrid models are producing much more practical solutions then process driven approaches. The advantage of deep learning algorithms is in finding solutions depending directrly on the historic data without a layer of abstraction, which often oversimplifies the problems.\nPRESENT FOREST TREES OF WORKS REGARDIGN APPLICABILITY FOR EACH SUBGROUP BASED ON PROBLEM DEFFINITION\n\n\n3.5.3.3 Complexity:\nOnly small portion of the research are considered complex with at least 0.8 of above score. One of the highly possible reasons for this is that even the authors who eventually build solutions for complex models start with the smaller simpler tasks to test their theory and understand the diractions of improvement. The mean value suggest that the researchers are still mostrly intrested in simple and midium-complexity models.\nPRESENT FOREST TREES OF WORKS REGARDIGN COMPLEXITY FOR EACH SUBGROUP BASED ON PROBLEM DEFFINITION\n\n\n\n3.5.4 Results of Sensitivity Analyses\nThe sensetivity analysis is condacted focusing on the quality and count of studies, and also on robustness, applicability, and complexity of the solutions. For the leveraging parameters the country income, population, and results of the PISO2014 international survey are taken into account. Also the model is available by the LINK which predicts the research state in the area of advanced computational methods for medical resource scheduling based on the input values underlined in the previous sentance. According to the results, the next trends can be seen below:\nPRESENT TWO VARIENTIONS OF PLOTS: (I) X AXES REPRESENTS INCOME, Y AXES REPRESENTS ONE OF 4 ASPECTS: QUALITY OF RESEARCH, ROBUSTNESS, APPLICABILITY, AND COMPLEXITY OF THE SOLUTIONS, SIZE OF THE BOOBLE REPRESENTS THE POPULATION SIZE; (II) X AXES SOME GENERAL PARAMETER FORM PISO2014, THE REST IS THE SAME AS IN THE PREVIOUS TYPE (I) PLOTS\nThe lack of information on published papers due to artificial limitation to only English emplies that the presented analysis is not full but still representative. The forest plots presented below show veriaty in the results.\nTHE RESULTS OF SENSITIVITY ANALYSES VISUALLY USING FOREST PLOTS\nThe outcomes of the sensitivity analysis are also generalised by analysing their heterogeneity.\nALSO CONSIDER SHOWING HETEROGENEITY PLOTS OR TABLES GENERALISING RESULTS FRON FOREST PLOTS"
  },
  {
    "objectID": "section/03_results.html#reporting-biases",
    "href": "section/03_results.html#reporting-biases",
    "title": "3¬† Results",
    "section": "3.6 Reporting Biases",
    "text": "3.6 Reporting Biases\nThere are high interest in the machine learning trends specially in deep learning, which clearly makes the research community favor these approaches over the other existing methods for medical resource scheduling. To investigate the existing biases when commes to synthesysing the advance computational system to support desicions of the healthcare managers the availability and the type of the outcomes of the studies are considered.\nThe percentyle of the possitive findings is much higher in research with deep learning approaches then in all other approchers. These may possibly indicate that the studies with the negative findings was not approved in reviewed journals, the results have been adjusted, or perspective on the outcomes have been shifted toward more favorable results. Just by difference between positive and negative outcomes it is impossible to state deffinatrly about the current situation in the medical resource scheduling.\nCHART WITH PERSENTAGES OF POSITIVE AND NEGATIVE OUTCOMES FOR DIFFERENT SOLUTION APPROACHES IN REGARD TO SPECIFIED PROBLEM, POSSIBLY HEAT MAP COULD BE USEFULL\nFor more in-depth analysis of the materials the solutions‚Äô advantages, disadavantages, and also the proofs of the authors statement have been collected for each publication which gone over the focus stage of the review. Based on the gathered data the quantitative assessments of risk of bias was conducted. The rate of the proffed statements to the overal namber of statements have been calculated for the problem-solution pares. The results of the analysis are displaied in the charts below.\nNUMBER OF CHARDS DEMONSTRATING RISK OF BIASES TOWARD PROS AND CONS OF EACH SOLUTION IN THE CORRESPONDED HEALTHCARE SCHEDULING PROBLEM"
  },
  {
    "objectID": "section/03_results.html#certainty-of-evidence",
    "href": "section/03_results.html#certainty-of-evidence",
    "title": "3¬† Results",
    "section": "3.7 Certainty of Evidence",
    "text": "3.7 Certainty of Evidence\nThe certainty of the evidence in the reviewed studies are rated with five-scale grade. Where are five critarias of certainty, each of the reached criteria gains a point of certainty to the reviewed material. The grading systems is created in the way that for most of the cases the next point of certainty can be gained if the requirements for the previous points are meat:\n\n1st point: The resutls of the research are mentioned in the body of the report paper with explanation how the results were obtained.\n2nd point: The process of reaching the findings of the study is clearly stated. The results are mention in body of the research and underlined in the conclusions of the work.\n3rd point: The output of the research is highlighted in the short summaries of the paper (abstract, conclusions, or discussions). The authors of the work presented the data in structured digestible form.\n4th point: The findings demonstrated with charts or tables, and there is a link to the manuscripts, research data, or additional supplimentary materials. However, the original data is not accessable, or in order to access the data, other researchers need to make a request, fully andertend the architecture of the storage platform, where the data was reserved.\n5th point: The results are presented in a table and the collected data during the research is fully available and easally accessable for the replication of the results by other investigators. The data in the presented tables is consistant with the values presented in the text and the raw data of the research.\n\nPROVIDE A TABLE OR/AND CHART WITH CERTAINTY GRADES FOR THE REVIEWED WORKS\nThe average certainty of the results is belove medium possible level on the certainty scale. The main reason for this is complications to get medical records available as open-source database. However, if researchers gave more attention to the reproducibility of the research, this score would be much higher even with the existing challenges in the healthcare industry.\nPROVIDE A DETAILED TABLE OR/AND CHART WITH CERTAINTY GRADES FOR THE REVIEWED WORKS RELATED TO THE LOCATION OR OTHER CHARACTERISTICS OF THE WORK"
  },
  {
    "objectID": "section/04_discussion.html#interpretation",
    "href": "section/04_discussion.html#interpretation",
    "title": "4¬† Discussion",
    "section": "4.1 Interpretation",
    "text": "4.1 Interpretation\n\n4.1.1 Stategy Decision Levels\nThe understanding of the decision levels important to understand what computational solutions will bring the most benefits on what decision level. The higher the level of desicion-making the more distant it is to actual human interaction and more matter of structuring numbers and deriving reasonable solutions from there. The lover levels, on the other hand, requires more human-like response and bieng present ‚Äúin the field‚Äù to make optimal decisions for the moment. Nevertheless, the understanding of the personnel actions from the strategic level is critical to produce realistic policies, regulations, and strutegies for the caregivers in-action.\nFrom the analysis of the available literature, it seams that the more computational approaches consentraited on the lower tactical and operational levels, where the efficient desicions from a computational system requires high efforts in ensuring the accurat, relevant, complete, and timely data. For higher tactical and stratagic levels there is more ‚Äúroom‚Äù for data to stay accurat, releven, and timely. Hense, it is high possibilities that if these scientific effords will be focused on the higher levels of decision-making, the value of these studies will drastically increase.\n\n\n4.1.2 Integration of the Scheduling Problem\nThe nature of research requires to ignore some variables regarding the investigated phenomena, but the medical resource scheduling is an NP-hard problem with numerous critaria. There is no study which will clearly define prorities of the different parts of medical resource scheduling. The reason for this, is that the scheduling problems in hospitals differ by funding, level of staff profissiancy, policies and regulations, and available data for analysis. The first issue which is need to be addressed is the medical records. Without medical records there is not idea where the hospital administration is trying to improve and what is realy important. But even here different hospitals may persuit different paths depending on what metrics should be measured: revenue, utilisation time, patient waiting time or patient and staff satisfaction‚Ä¶ ???\nThe literature proposes for the most cases narrow approach to the scheduling problem. With the growth of the constrains the problem becomes more complex to find sufficient solutions and therefore the number of publications plummets down. It is not a rational to try to put as many as possible constraints in the scheduling models. Therefore, it is need to develop an approach of definning the most valuable aspects of the problem to the liest valuable. Desiding what parameters are more valuable than the other can be multi-objective task itself. For example, the hospital administration may consider gains form the improving sertain critaria, required resources to measure the critaria, complexity of the analysation of the measured data, what other critarias may be influance by increase of the chosen parameter, and finaly needed components to improve the certain parameters of the healthcare services in this hospital. Because this is an over-complicated task for itself, most of the hospitals either go with the simplest critatia to track and work with whatever data theu will gain in the process, or copy the paths of hospitals with the well established criterias. Both of the choises are valid practical approaches.\n\n\n4.1.3 Upstream and Downstream Capacities\nThe management of capacities related to the operating theatres is crucial to avoid blocking the opearing theatre even though the surgery is over, but new case cannot be allowed in the theatre by numerouse possible reasons. Here the computational systems can be usefull in keeping track of available beds, nurses, and anaesthegiologists in preoperative and postoperative units. It involves the suffisticated records system which allow to undertand occupancy of the available resources. Without it a planning of the operation cases and other healthcare services is ‚Äúgoing blind in a maze‚Äù, but with the habits of recording the state of the upstream and downstream capacities the computational approaches can bring analysis of the demands and therefore propose strategies for planning of the needed capacities. However, the on-the-fly desicions cannot be supported by the automated advisory systems. The best method dealing with the critical unavailability of the resources is to have policies of prioritisations of these resources prepared beforehand. To ensure that the policies are working the medical stuff should be trained to follow the policies in critical situations. ???\n\n\n4.1.4 Types of Patients\nThere is significant inbalance in research dedicated to elective and non-elective patients. The non-elective patients are not considered for the most cases. The reason for this that most authors asumen that the hospitals would have dedicated capacity for emergent cases, which is not always the case. The dedicated emergency theatre is capacity which is consumes a lot of resources to maintain and for the most time stands idel. That makes the separate non-elective patients care suboptimal in terms of efficient medical resource utilisation. This itself raises the importance of the research for non-elective surgery cases to the same level as the elective cases if not makes even more crusial to investigate. The managing of emergent cases is a challenge for medical resource scheduling system for its unpredictability. Newertheless, with sufficient datasets of medical records it will be or even is possible to predict using modern machine learning techniques.\nThe studies which focuse on emergent cases there is clear understanding that there are veriaty of protocols regarding how to identify urgency level of the surgery and what actions should be made. Difference in hospitals‚Äô policies and regulations is the main reason why there is still no unified, correct approach of managing non-elective cases. The evailability of hospital records as well as generalisation protocols will drastically increase the efficiency in how hospitals administration prepares and allocates emergency cases.\nShifting to the classification of the patients by hospitalisation. The inpatients and outpatiens for the most studies are treated the same. However, the ambulatory and surgery outpatients are differ from the inpatients because they can just not come to the appointed event. In the literature these aspect is studied separatly for general surgery scheduling and for most of the cases is resulved by prediction models and overbooking the resources required for the event (consultation, ambulatory analysis, and surgery) for the events with high risk of no-show. From the perspective of the hospitals there is also possibility of cancellations with reasons unrelated to a particular appointment event. With this in mind, the study which will consider the uncertainty of cancellation of the events while focusing on the medical resource planning and allocation would bring additional insights on the possible improvement in the healthcare management.\n\n\n4.1.5 Who Got All the Brains?\nThe United States of America lieding in the number of publications and the number of implemented solutions. The US shows desire and finantial and technical cababilities to progress in the more efficient healthcare management. It is hard to compare a quality of the proposed solutions due to diversity of approaches but tomorrow‚Äôs statistics will show the results of the efficiency of the menegement systems implemented today. The second by quantity of the produces research in the medical scheduling is China. There have been found no research from numerous of countries. The majority of these countries have small- or midle-size economies. Since the implementation requires money to build infrastructure for effective medical recording system and on top of that the advance healthcare management is possible. However, money is just a half of the recepie: the efficient implementations of innovations from the operations research requires high-level of profficiency from caregivers and hospital administration staff.\n\n\n4.1.6 Quality of Research\nThe results yiel a high percentage of misconduct and unresponsible research practicies. The reviewed papers are for the most part quantitative analysis of the produced scheduling or analysing approaches. Therefore, the outputs are models and comparisons to the existed prior solutions. Newertheless, part of the publications do not state the objectives of the research, do not present comparative analysis, and some even forgot to evaluate own models. Additionaly, hardships on getting medical records published for the open-access makes it impossible to replicate the published study to prove its valuability oe highlight mistakes. The absents of the key components of the research shows need in training of qualified scientists."
  },
  {
    "objectID": "section/04_discussion.html#limitations-of-evidence",
    "href": "section/04_discussion.html#limitations-of-evidence",
    "title": "4¬† Discussion",
    "section": "4.2 Limitations of Evidence",
    "text": "4.2 Limitations of Evidence\nThere is critical situation with prooving the performance results and achievements of the developed scheduling solutions, since most of the papers do not give access to the research data to be able to reproduce the gained results. The reasons for the studies with implementation of the solutions in real hospitals are known and related to policies and regulations regarding sharing sensitive medical information publically. To the publications which use artificial datasets for tests and evaluation the responsibility for pure research practice is on the researchers. The lack of the replicable studies is one of the main reasons for exponantial growth of the publications but inability to build robast and applicable scheduling models."
  },
  {
    "objectID": "section/04_discussion.html#limitations-of-review-processes",
    "href": "section/04_discussion.html#limitations-of-review-processes",
    "title": "4¬† Discussion",
    "section": "4.3 Limitations of Review Processes",
    "text": "4.3 Limitations of Review Processes\nThis study covers only five most known databases in medicine, computer science, and general research. There are numerous less known datasets from academic and commersial domains which are not included into the survey. Furthermore, the software solutions which is already offers services to hospitals may cover some or even all the functionality discussed in the research, but nothing even remotly similar was found duren the analysis of the business articles on the medical innovations. Therefore this matter requires separate dedicated investigation with in depth communication with the users and the developers of the softwere solutions.\nThe publications between 2020 and 2023 got the most attention. By trasting the earlier literature reviews and systematically analysing the resent works the core tandency of the medical resource scheduling was outline in this systematic review. There is still a small possibility of the valuable work in the set of unread articles and even not popular poblucations have valuable aspects in them. Therefore, the scoped literature represent general idea of the situation, but by no meens it is the full picture of the current situation in the industry.\nWith focus on operating theatre scheduling in mind, the elements of healthcare which has little to no influance to the patient flow in surgery departments have been filtered out on the scanning process. This excludes research in areas of drag supply chain optimisation, ambulance decision making, home healthcare, ambulatory results analysis, and prescription analysis.\nThe scanning, reviewving, and analysis of the studies was done by one person which indicated high chance of biased conclusions. In order to minimise the one-side view on the reviews works the summaries and the notes of reviewing author together with the estimation of the level of comprehension are available for review and comments. The authors highly uncorage not blibdly believe the conucted work but look into origins of the results to build more deep undestanding unbised from the proposed conlusions."
  },
  {
    "objectID": "section/04_discussion.html#implications",
    "href": "section/04_discussion.html#implications",
    "title": "4¬† Discussion",
    "section": "4.4 Implications",
    "text": "4.4 Implications\n\n4.4.1 Sharing the Knowledge\nAs it was seen from the results even though the number of the published papers grown drastically for the last three years, the precental of the studies which offer reproducebility of the research even worthen. Here could be multiple resons for such behaviour. First, the practical medical resource scheduling requires access to some medical recorts to make proper validation of the proposed solution. A medical record is sensitive data. To be able to share it, the data should be properly anonymised and the research on the data should be approved by data provider and local laws regarding data review, collection, and sharing. Getting all ligal documents consums a lot of time and effords. Lieading, for most cases, to not bothering with reproducibility of the research in the first place. Second probable reason for lack of reproducible research is deliberate or unvoluntary neglaction of this aspect of the research conduct by the authrors. Finnaly, lack of knowledge to create a reproducible study.\nThere is a viable set of actions to address the problem with medical records. The data administrators in hospitals or researchers, who already has access to medical records, can preprocess the data to ‚Äúunlink‚Äù the personal data from the datasets and preserve the optimsal structure for further development of the research. Since most of the hospitals even in the same country has different policies and regulations regarding the volume of the data and the recording process, the more different datasets will become available in open-source, the easier it will be to create new robust, optimsal scheduling solutions\nFor the second and the third resons of not conducting proper research, the best approach is to increase awareness of the research teams in their institutions by providing sufficient training. Probably, increase appealing learning resources in the pablic area such as social media, television, etc. Particularly, regarding the researchers who deliberetly misconduct their works, the consiquences of such behaviour can be discussed in public media.\n\n\n4.4.2 No ultimate solutions\nWhat is meant by not optimal solutions? There are either generalisable but not applicable studies or vise-versa. The main reason for this is discussed in the previous subsection, but enother issue is in nerrow foucus on the scheduling problem of one specific resource. The operating theatre planning and scheduling is integrated problem as well as nurse rostering and patient appointment allocation. These problems are interconnected and by ignoring this fact the designed automated soltions become unscalable or unapplicable. Ensuring thet the scheduling system can propose a sufficient solutiont withouth bank of medical records and enhance the scheduling slowely and steadally as the more and more medical records become available to the system is the approach which will produce reproducible, generalised results for multiple departments and hospitals worldwide.\nThe raise of the machine learning in health industry brought critical questions regarding desicions made by machines. There are to sides to these concerns: responsibility of the developers of the schedulig system and responsobility by healthcare proffesionals who use the software. As it is right now, the best approach is to consider any automated desicion-macking tools as advisors not a final instance for the choice. In this way the machine learning systems will guide proffesionals to reach better healthcare performance and reduce risk and concequences of a mistake for interns."
  },
  {
    "objectID": "section/05_other_information.html#registration",
    "href": "section/05_other_information.html#registration",
    "title": "5¬† Other Information",
    "section": "5.1 Registration",
    "text": "5.1 Registration\nThis systematic review is not pre-registered in any database."
  },
  {
    "objectID": "section/05_other_information.html#protocol",
    "href": "section/05_other_information.html#protocol",
    "title": "5¬† Other Information",
    "section": "5.2 Protocol",
    "text": "5.2 Protocol\nThe current work follows the guidance from established template for systematic literature review in medicine ‚ÄîLINK/ CITATION/ ETC.‚Äî."
  },
  {
    "objectID": "section/05_other_information.html#amendments",
    "href": "section/05_other_information.html#amendments",
    "title": "5¬† Other Information",
    "section": "5.3 Amendments",
    "text": "5.3 Amendments\nSo far it is only a draft of the study. It is expected to be numerouse changes before the print ready version of the article."
  },
  {
    "objectID": "section/05_other_information.html#support",
    "href": "section/05_other_information.html#support",
    "title": "5¬† Other Information",
    "section": "5.4 Support",
    "text": "5.4 Support\nThis literature review was produced with the financial support of the Science Foundation Ireland Centre for Research Training in Artificial Intelligence under Grant No.18/CRT/6223. This literature review has emanated from research conducted with the financial support of Science Foundation Ireland under Grant number 18/CRT/6223. For Open Access, the author has applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission."
  },
  {
    "objectID": "section/05_other_information.html#competing-interests",
    "href": "section/05_other_information.html#competing-interests",
    "title": "5¬† Other Information",
    "section": "5.5 Competing Interests",
    "text": "5.5 Competing Interests\nOleksii Dovhaniuk is a PhD researcher at the University College Cork in the School of Computer Science and Information Technology. Dr Sabin Tabirca is a senior lector of the University College Cork in the same department. It is only natural that automated computational methods will get more attention than classical approaches to medical resource scheduling. Furthermore, the Science Foundation Ireland Centre for Research Training in Artificial Intelligence requires progress in advanced computational methods, which narrows the interest even more in the direction of machine learning, neural networks, and meta-heuristics. The authors who represent the medical area of the research are either former workers of the Transformation Theatre Team in Ireland or closely related to this initiative. This aspect makes the research orient into operating theatre as the central aspect of medical resource scheduling. The weaker the connection of medical resources to the surgery operations, the less attention they get during the literature analysis."
  },
  {
    "objectID": "section/05_other_information.html#availability-of-data-code-and-other-materials",
    "href": "section/05_other_information.html#availability-of-data-code-and-other-materials",
    "title": "5¬† Other Information",
    "section": "5.6 Availability of Data, Code, and Other Materials",
    "text": "5.6 Availability of Data, Code, and Other Materials\nList of studies which were read, analysed but rejected in the final manuscript can be accessed by link to the GitHub repository. In the same repository the R code for automatic mining the metadate from the BibTex references is available. The suplimentary materials such as preliminary tables, charts as well as final results are published on the separate web page."
  },
  {
    "objectID": "section/05_other_information.html#author-contribution-statements",
    "href": "section/05_other_information.html#author-contribution-statements",
    "title": "5¬† Other Information",
    "section": "5.7 Author Contribution Statements",
    "text": "5.7 Author Contribution Statements\nOleksii Dovhaniuk scanned, structured, and analysed literature and rendered the draft. Grace Reidy, Charlie Dineen, and Mark Corrigan problem formulation and advisory. Sabin Tabirca, mid-project and final assessments. All authors discussed the results and contributed to the final manuscript."
  }
]